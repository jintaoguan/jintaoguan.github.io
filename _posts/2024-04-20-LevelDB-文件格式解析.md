---
layout:     post
title:      LevelDB 数据格式解析(1)
date:       2024-04-20
author:     Jintao
header-img: img/post-bg-2015.jpg
catalog: true
tags:
    - LevelDB
---

## 概述
在 LevelDB 中存在各种类型的数据，每一种数据都使用了特定的存储格式，并且这些格式都被其他的数据库引擎继承并扩展，比如 Facebook 开发的的 RocksDB，又比如 CockroachDB 在使用的单机存储引擎 pebble，它们使用的都是 LevelDB 的文件格式。所以学习并理解 LevelDB 的数据格式以及为什么这样设计有助于我们对于这些存储引擎源码的学习。我们知道 LevelDB 是一种基于 operation log 的存储系统，是 Log-Structured-Merge Tree 的典型实现。我们会介绍 LevelDB 中使用多种数据格式，比如各种 Key 的表示，日志文件 (Write-Ahead-Log)，SSTable 文件，MemTable 与跳表 (SkipList) 等等。

## LevelDB 基本数据结构

#### Slice
Slice 是 Leveldb中的基本数据结构，包括 length 和一个指向外部字节数组的指针。和 string 一样，允许字符串中包含 ’\0’。提供一些基本接口，可以把 const char 和 string 转换为 Slice，把 Slice 转换为 string，取得数据指针 const char。
~~~c++
class LEVELDB_EXPORT Slice {
  public:
    // public methods ...
  private:
    const char* data_;
    size_t size_;
};
~~~

#### Status
Status 是 Leveldb 中的返回状态，将错误号和错误信息封装成 Status 类，统一进行处理。并定义了几种具体的返回状态，如成功或者文件不存在等。为了节省空间 Status 并没有用 std::string 来存储错误信息，而是将返回码 (code), 错误信息 message 及长度打包存储于一个字符串数组中。成功状态 OK 是 NULL state_，否则 state_ 是一个包含如下信息的数组:

~~~c++
state_[0..3] // 消息message长度 
state_[4]    // 消息code
state_[5..]  // 消息message 
~~~

#### Arena
Arena 是 LevelDB 的简单的内存池，它所作的工作十分简单，申请内存时，将申请到的内存块放入 std::vector blocks_ 中，在 Arena 的生命周期结束后，统一释放掉所有申请到的内存，Arena没有直接调用 delete/free 函数，而是由 Arena 的析构函数统一释放所有的内存。

#### SkipList
SkipList (跳表) 是一种可以代替平衡树的数据结构。SkipList 应用概率保证平衡，平衡树采用严格的旋转（比如平衡二叉树有左旋右旋）来保证平衡，因此 SkipList 比较容易实现，而且相比平衡树有着较高的运行效率。从概率上保持数据结构的平衡比显式的保持数据结构平衡要简单的多。对于大多数应用，用 SkipList 要比用树更自然，算法也会相对简单。由于 SkipList 比较简单，实现起来会比较容易，虽然和平衡树有着相同的时间复杂度 (O(logn))，但是SkipList 的常数项相对小很多。SkipList 在空间上也比较节省。一个节点平均只需要1.333个指针（甚至更少），并且不需要存储保持平衡的变量。

## 各类 Key 的结构
LevelDB 是一个 Key-Value 存储，但是在 LevelDB 中对于 Key 有多种不同形式的表示与存储结构。

#### User Key, InternalKey 和 ParsedInternalKey 
`User Key`也就是用户定义的，任意长度内容的 Key，用来读取之前写入数据库的 Value。

`InternalKey` 是一个复合概念，是有几个部分组合成的一个key，`ParsedInternalKey`就是对`InternalKey`分拆后的结果，先来看看`ParsedInternalKey`的成员，这是一个 struct：
~~~c++
typedef uint64_t SequenceNumber;
enum ValueType { kTypeDeletion = 0x0, kTypeValue = 0x1 };

struct ParsedInternalKey {
  Slice user_key;
  SequenceNumber sequence;
  ValueType type;
}
~~~
也就是说 `InternalKey` 是由 (`User Key` + `Sequence Number` + `Value Type`) 组合而成的，顺便先分析下几个 Key 相关的函数，它们是了解Internal Key 和 User Key 的关键。
~~~c++
class InternalKey {
  public:
    // public methods ...
  private:
    std::string rep_;
}
~~~

从`InternalKey`的定义可以看到，它只有一个变量`rep_`，存储的就是一段 byte array。有以下两个方法可以进行的转换。
~~~c++
// 解析 InternalKey （一段字节数组）并转换成 ParsedInternalKey
bool ParseInternalKey(const Slice& internal_key, ParsedInternalKey* result) {
  const size_t n = internal_key.size();
  if (n < 8) return false;
  uint64_t num = DecodeFixed64(internal_key.data() + n - 8);
  uint8_t c = num & 0xff;
  result->sequence = num >> 8;
  result->type = static_cast<ValueType>(c);
  result->user_key = Slice(internal_key.data(), n - 8);
  return (c <= static_cast<uint8_t>(kTypeValue));
}

// 将 ParsedInternalKey 转换成字节数组，并写到 result 里
void AppendInternalKey (std::string* result, const ParsedInternalKey& key) {
  result->append(key.user_key.data(), key.user_key.size());
  PutFixed64(result, PackSequenceAndType(key.sequence, key.type));
}
// 将 ParsedInternalKey 的 SequenceNumber 和 ValueType 组合成最后 8 个连续字节
static uint64_t PackSequenceAndType(uint64_t seq, ValueType t) {
  assert(seq <= kMaxSequenceNumber);
  assert(t <= kValueTypeForSeek);
  return (seq << 8) | t;
}
~~~

根据这两个方法的实现，容易得到`InternalKey`的格式（即`rep_`数据的格式）。

**InternalKey 的格式**：
```
| User Key (string) | Sequence Number (7 bytes) | Value Type (1 byte) |
```

值得注意的是，`User Key`是任意长度的，但是这个`InternalKey`中是**不存储 User Key 的长度的**。我猜原因是`InternalKey`只用于内存中表示 Key，往往用 Slice 进行表示，而不需要序列化到磁盘上或者从磁盘反序列化到内存中，所以不需要记录长度信息。
由此还可知道sequence number大小是7 bytes，sequence number是所有基于op log系统的关键数据，它唯一指定了不同操作的时间顺序。

把`User Key`放到**前面**的原因是，这样对同一个 user key 的操作就可以按照 sequence number 顺序连续存放了。另外用户可以为 user key 定制比较函数，系统默认是字母序的。如果按照默认字母序进行排序的话，相同的 user key 的操作 (不同的 sequence number 和 value type) 会被放在一起。

#### LookupKey 和 Memtable Key
首先我们来了解 `LookupKey`。MemTable 的查询接口传入的是`LookupKey`，它也是由 User Key 和 Sequence Number 组合而成的。

**LookupKey 的格式**：
```
| Size (Varint32) | User Key (string) | Sequence Number (7 bytes) | Value Type (1 byte) |
```

可以看出这里`LookupKey`和之前`InternalKey`的唯一区别就是`LookupKey`在头部用 Varint32 变长方法**存储了后面的 InternalKey 的长度**，大约占用 1 到 5 个字节。这里的 Size 是 **(user_key.size() + 8)**，也就是对应的 InternalKey 的长度了。另外这里 value type 是`kValueTypeForSeek`，它等于`kTypeValue`。LookupKey的定义如下：
~~~c++
class LookupKey {
  public:
    // public methods ...
  private:
    // We construct a char array of the form:
    //    klength  varint32               <-- start_
    //    userkey  char[klength]          <-- kstart_
    //    tag      uint64                 <-- 8 bytes: sequence + type
    //                                    <-- end_
    // The array is a suitable MemTable key.
    // The suffix starting with "userkey" can be used as an InternalKey.
    const char* start_;
    const char* kstart_;
    const char* end_;
    char space_[200];  // Avoid allocation for short keys
};

LookupKey::LookupKey(const Slice& user_key, SequenceNumber s) {
  size_t usize = user_key.size();
  size_t needed = usize + 13;  // A conservative estimate
  char* dst;
  if (needed <= sizeof(space_)) {
    dst = space_;
  } else {
    dst = new char[needed];
  }
  start_ = dst;
  dst = EncodeVarint32(dst, usize + 8);   // klength = user_key.size() + 8 
  kstart_ = dst;
  std::memcpy(dst, user_key.data(), usize);
  dst += usize;
  EncodeFixed64(dst, PackSequenceAndType(s, kValueTypeForSeek));
  dst += 8;
  end_ = dst;
}
~~~

LookupKey 导出了三个函数，可以分别从 LookupKey 得到 Internal Key，Memtable Key 和 User Key，如下：
~~~c++
// Return a key suitable for lookup in a MemTable.
Slice memtable_key() const { return Slice(start_, end_ - start_); }

// Return an internal key (suitable for passing to an internal iterator)
Slice internal_key() const { return Slice(kstart_, end_ - kstart_); }

// Return the user key
Slice user_key() const { return Slice(kstart_, end_ - kstart_ - 8); }
~~~

从上面`memtable_key()`方法的实现可以看出来，`LookupKey`和`Memtable Key`其实表达的是相同的概念。

## 日志文件格式
日志文件是 LevelDB 也是所有  Log-Structured-Merge Tree 数据库的重要组成部分。所有的写操作都必须先成功的append到操作日志中，然后再更新内存memtable。这样做有两点好处：
- 可以将**随机写**变成**顺序写**，极大的提高写的速度；
- 在节点down机后，内存数据消失，系统可以在重启后根据日志恢复内存数据继续服务，从而避免内存数据丢失。

LevelDB将日志文件按照 32KB 的 Block 进行分块操作，每次读取的单位也是以一个 Block 作为基本读取单位（以 block 为基本单位读取的好处是什么？）。阅读源码后可知，Log 文件由以下层级构成：
- 每个`Log文件`包含多个`Block`，每个 Block (32 KB)。
- 每个`Block`包含多条`Log`， Log 可以为完整的一条，也可以是不完整的（前半部分/后半部分/中间部分），因为 Block 是固定 32 KB
- 每条`Log`数据由`header`和`data`构成。
- `header`长度是固定的 7 bytes，由 CRC（4 bytes）, Log length（2 bytes），Log type （1 byte）构成。
- `data`是任意长度。

**单条 Log 数据格式**：
```
| CRC (4 bytes) | Length (2 bytes) | Type (1 byte) | Data |
```

Header 中的这个占用一个字节的`type`是什么呢？我们知道 Block 是固定 32 KB，而 Log 的长度是任意的（因为用户的 Key 和 Value 长度是任意的），所以一个 Block 有可能存放多条完整的 Log，也有可能存放不完整的 Log（前半部分/后半部分/中间部分），所以`type`用来标记这个一条完整的 Log 还是一条不完整的 Log，如果是不完整的 Log，那么它是前半部分，后半部分还是中间部分？
~~~c++
namespace log {
enum RecordType {
  // Zero is reserved for preallocated files
  kZeroType = 0,

  kFullType = 1,

  // For fragments
  kFirstType = 2,
  kMiddleType = 3,
  kLastType = 4
};
static const int kMaxRecordType = kLastType;
static const int kBlockSize = 32768;
// Header is checksum (4 bytes), length (2 bytes), type (1 byte).
static const int kHeaderSize = 4 + 2 + 1;
}
~~~

因为 Log 的 header 就占用了 7 bytes，那么当一个 Block 在存放完上一条 Log 之后只剩下 6 bytes 或者更少时，就不再继续使用当前 Block，并且使用`'\0'`填充剩下的空间，所以在 Block 最后最多可以看到 **6个连续的 '\0'**。

**Log 文件格式**：
![](/img/post-img/2024-04-20/leveldb_log_format.png)

作者在`/leveldb/doc/log_format.md`举了一个例子：
```
Example: consider a sequence of user records:

    A: length 1000
    B: length 97270
    C: length 8000

**A** will be stored as a FULL record in the first block.

**B** will be split into three fragments: first fragment occupies the rest of
the first block, second fragment occupies the entirety of the second block, and
the third fragment occupies a prefix of the third block.  This will leave six
bytes free in the third block, which will be left empty as the trailer.

**C** will be stored as a FULL record in the fourth block.
``` 

- 第一条 Log A：长度是 1000 字节。加上 header 之后在第一个 Block 中占用 1000 + 7 = 1007 字节，第一个 Block 剩余 32 * 1024 - 1007 = 31761 字节。
- 第二条 Log B：长度是 97270 字节。第一个 Block 中剩余 31761 字节，先存储 header (7 bytes)，再存储 Log (31754 bytes)。因为 Log 没有结束，新开一个 Block。在第二个 Block 中，先存储 header (7 bytes)，再存储 Log (32761 bytes)，Log 还没有结束，新开第三个 Block。Log 还剩余 97270 - 31754 - 32761 = 32755 字节。在第三个 Block 中，先存储 (7 bytes)，在存储 Log (32755 bytes)，Log结束。第三个 Block 剩余空间为 32768 - 7 - 32755 = 6 字节，无法继续使用，全部用`'\0'`进行填充。
- 第三条 Log C：由于第三个 Block 已经结束，新开第四个 Block。在第四个 Block 中完整存储 Log C，剩余 32768 - 7 - 8000 = 24761 字节。

格式如下：
```
Block 1: | Log A header (7 bytes) | Log A data (1000 bytes) | Log B header (7 btyes) | Log B data (31754 bytes) |
Block 2: | Log B header (7 bytes) | Log B data (32761 bytes) |
Block 3: | Log B header (7 bytes) | Log B data (32755 bytes) | \0\0\0\0\0\0 (6 bytes) |
Block 4: | Log C header (7 bytes) | Log C data (7000 bytes) | ...
```

## 写日志操作
写比读简单，而且写入决定了读，所以从写开始分析。是在写日志文件时，LevelDB 使用了内存映射文件。cmu15-445 公开课中，Andy Pavlo 多次强调了在数据库实现中使用内存映射技术会导致很多问题。但是这里 LevelDB 使用内存映射我猜是因为这里是 append-only 写 Log 文件而不是 in-place 修改磁盘上的 page？

写日志操作的代码在`/leveldb/db/log_writer.cc`和`/leveldb/db/log_writer.h`中，它主要实现了一个`Writer`，唯一的接口是`AddRecord()`。
~~~c++
class Writer {
  public:
    // public methods ...
  private:
    WritableFile* dest_;
    int block_offset_;  // Current offset in block
    uint32_t type_crc_[kMaxRecordType + 1];
};
~~~
- `dest_` 是当前日志文件指针。
- `block_offset_` 是当前 Block 的 offset，可以用于计算当前 Block 剩余空间。
- `type_crc_[]` 是提前计算好的 crc 值，每一种`Type`(`kZeroType`,`kFullType`,`kFirstType`,`kMiddleType`,`kLastType`)都对应一个。

~~~c++
Status Writer::AddRecord(const Slice& slice) {
  const char* ptr = slice.data();  // 写入的日志数据开始地址
  size_t left = slice.size();      // 写入的日志的长度

  // Fragment the record if necessary and emit it.  Note that if slice
  // is empty, we still want to iterate once to emit a single
  // zero-length record
  Status s;
  bool begin = true;               // begin == true 表示从头开始写入新日志
  do {
    const int leftover = kBlockSize - block_offset_; // 计算当前 block 的剩余空间
    assert(leftover >= 0);
    if (leftover < kHeaderSize) {  // 如果剩余空间 <= 6 bytes，全部用 '\x00' 填充
      // Switch to a new block
      if (leftover > 0) {
        // Fill the trailer (literal below relies on kHeaderSize being 7)
        static_assert(kHeaderSize == 7, "");
        dest_->Append(Slice("\x00\x00\x00\x00\x00\x00", leftover));
      }
      block_offset_ = 0;
    }

    // Invariant: we never leave < kHeaderSize bytes in a block.
    assert(kBlockSize - block_offset_ - kHeaderSize >= 0);

    const size_t avail = kBlockSize - block_offset_ - kHeaderSize;  // 存储 header 后剩余空间
    const size_t fragment_length = (left < avail) ? left : avail;   // 当前 Block 可以写的日志长度

    RecordType type;
    const bool end = (left == fragment_length);   // end == true 表示写入日志的最后部分
    if (begin && end) {       // kFullType，表示一条完整的日志，从头写到尾
      type = kFullType;
    } else if (begin) {       // kFirstType，表示写了头，剩余空间不够，会在下一个 Block 继续存储这条 Log
      type = kFirstType;
    } else if (end) {         // kLastType，表示头在之前的 Block，当前 Block 存储了 Log 的最后部分
      type = kLastType;
    } else {                  // kMiddleType，表示非头非尾，当前 Log > 32 KB，占用了整整一个 Block
      type = kMiddleType;
    }

    s = EmitPhysicalRecord(type, ptr, fragment_length); // 向日志文件 dest_ 写入 header 和 fragment_length 长度的数据
    ptr += fragment_length;       // 偏移 ptr，调整还没写的 Log 数据
    left -= fragment_length;      // 调整还没写的 Log 长度
    begin = false;                // 在下一个 Block 中继续存储当前 Log 剩余数据
  } while (s.ok() && left > 0);
  return s;
}
~~~
其中调用了方法`EmitPhysicalRecord()`向当前的向日志文件中写入`header`和`fragment_length`长度的日志数据，并且强制写入到磁盘上，防止写操作被 buffer 导致丢失数据。在这里，只会写入当前 Block，如果 Log 数据过大或者当前 Block 剩余空间很小时，也只会写入 Log 的一部分，使当前 Block 被写满。这条 Log 剩余的数据则在下一次循环，在一个新的 Block 中继续写入。所以一条 Log 也许会导致`Flush()`被调用多次。

~~~c++
Status Writer::EmitPhysicalRecord(RecordType t, const char* ptr,
                                  size_t length) {
  assert(length <= 0xffff);  // Must fit in two bytes
  assert(block_offset_ + kHeaderSize + length <= kBlockSize);

  // Format the header
  char buf[kHeaderSize];                       // header (7 bytes)
  buf[4] = static_cast<char>(length & 0xff);   // length (2 bytes)
  buf[5] = static_cast<char>(length >> 8);
  buf[6] = static_cast<char>(t);               // type (1 byte)

  // Compute the crc of the record type and the payload.
  uint32_t crc = crc32c::Extend(type_crc_[t], ptr, length);
  crc = crc32c::Mask(crc);  // Adjust for storage
  EncodeFixed32(buf, crc);

  // Write the header and the payload
  Status s = dest_->Append(Slice(buf, kHeaderSize));   // 将 header 写入当前日志文件 dest_
  if (s.ok()) {
    s = dest_->Append(Slice(ptr, length));     // 将 length 长度的日志数据写入 dest_
    if (s.ok()) {
      s = dest_->Flush();                      // 写完日志后，强制刷写到磁盘上，防止被 buffer
    }
  }
  block_offset_ += kHeaderSize + length;       // 调整当前 Block 的 offset
  return s;
}
~~~
看了代码之后，有一个疑问，在`AddRecord()`和`EmitPhysicalRecord()`我们并没有看到 Block 的切换？那是因为两个 Block 之间没有任何标志，Block 只是 Log 文件的逻辑划分，所以`block_offset_ = 0;`就表示了使用一个新的 Block。

## 读日志操作
日志读取比写入要复杂，要检查checksum，检查是否有损坏等等，处理各种错误。
代码实现在``/leveldb/db/log_reader.h``和`/leveldb/db/log_reader.cc`中，它主要实现了一个`Reader`：
~~~c++
class Reader {
  public:
    // other public methods ...
    bool ReadRecord(Slice* record, std::string* scratch);
  private:
    SequentialFile* const file_;
    Reporter* const reporter_;
    bool const checksum_;
    char* const backing_store_;
    Slice buffer_;   // 读取的内容
    bool eof_;       // 上次Read()返回长度< kBlockSize，暗示到了文件结尾EOF
    uint64_t last_record_offset_;    // 函数ReadRecord返回的上一个record的偏移
    uint64_t end_of_buffer_offset_;  // 当前的读取偏移
    uint64_t const initial_offset_;  // 偏移，从哪里开始读取第一条record
    bool resyncing_;
};
~~~

`Reader`只有一个接口，那就是`ReadRecord()`，下面来分析下这个函数：
~~~c++
bool Reader::ReadRecord(Slice* record, std::string* scratch) {
  if (last_record_offset_ < initial_offset_) {     // 当前偏移 < 指定的偏移，需要Seek
    if (!SkipToInitialBlock()) {
      return false;
    }
  }

  scratch->clear();
  record->clear();
  bool in_fragmented_record = false;       // 判断 Log 是否被截断，分散在多个 Block 中
  // Record offset of the logical record that we're reading
  // 0 is a dummy value to make compilers happy
  uint64_t prospective_record_offset = 0;  // 我们正在读取的逻辑record的偏移

  Slice fragment;
  while (true) {
    const unsigned int record_type = ReadPhysicalRecord(&fragment);

    // ReadPhysicalRecord may have only had an empty trailer remaining in its
    // internal buffer. Calculate the offset of the next physical record now
    // that it has returned, properly accounting for its header size.
    uint64_t physical_record_offset =
        end_of_buffer_offset_ - buffer_.size() - kHeaderSize - fragment.size();

    if (resyncing_) {
      if (record_type == kMiddleType) {
        continue;
      } else if (record_type == kLastType) {
        resyncing_ = false;
        continue;
      } else {
        resyncing_ = false;
      }
    }

    switch (record_type) {
      case kFullType:
        if (in_fragmented_record) {
          // Handle bug in earlier versions of log::Writer where
          // it could emit an empty kFirstType record at the tail end
          // of a block followed by a kFullType or kFirstType record
          // at the beginning of the next block.
          if (!scratch->empty()) {
            ReportCorruption(scratch->size(), "partial record without end(1)");
          }
        }
        prospective_record_offset = physical_record_offset;
        scratch->clear();
        *record = fragment;
        last_record_offset_ = prospective_record_offset;
        return true;

      case kFirstType:
        if (in_fragmented_record) {
          // Handle bug in earlier versions of log::Writer where
          // it could emit an empty kFirstType record at the tail end
          // of a block followed by a kFullType or kFirstType record
          // at the beginning of the next block.
          if (!scratch->empty()) {
            ReportCorruption(scratch->size(), "partial record without end(2)");
          }
        }
        prospective_record_offset = physical_record_offset;
        scratch->assign(fragment.data(), fragment.size());
        in_fragmented_record = true;
        break;

      case kMiddleType:
        if (!in_fragmented_record) {
          ReportCorruption(fragment.size(),
                           "missing start of fragmented record(1)");
        } else {
          scratch->append(fragment.data(), fragment.size());
        }
        break;

      case kLastType:
        if (!in_fragmented_record) {
          ReportCorruption(fragment.size(),
                           "missing start of fragmented record(2)");
        } else {
          scratch->append(fragment.data(), fragment.size());
          *record = Slice(*scratch);
          last_record_offset_ = prospective_record_offset;
          return true;
        }
        break;

      case kEof:
        if (in_fragmented_record) {
          // This can be caused by the writer dying immediately after
          // writing a physical record but before completing the next; don't
          // treat it as a corruption, just ignore the entire logical record.
          scratch->clear();
        }
        return false;

      case kBadRecord:
        if (in_fragmented_record) {
          ReportCorruption(scratch->size(), "error in middle of record");
          in_fragmented_record = false;
          scratch->clear();
        }
        break;

      default: {
        char buf[40];
        std::snprintf(buf, sizeof(buf), "unknown record type %u", record_type);
        ReportCorruption(
            (fragment.size() + (in_fragmented_record ? scratch->size() : 0)),
            buf);
        in_fragmented_record = false;
        scratch->clear();
        break;
      }
    }
  }
  return false;
}
~~~


开始时调用的 `SkipToInitialBlock()` 方法的实现如下，它的作用是调整 `end_of_buffer_offset_` 到当前 Block 的开始位置，并且通过调用 `file_->Skip(block_start_location)` 跳过之前已经读过的所有 Block，seek 到当前 Block 的起始位置。如果当前是第一个 Block，则不进行 seek，从文件的第一个字节开始读。开始读取日志的时候都要保证读取的是完整的block，这就是调整的目的。
~~~c++
bool Reader::SkipToInitialBlock() {
  const size_t offset_in_block = initial_offset_ % kBlockSize;  // 在当前 Block 中的 offset
  uint64_t block_start_location = initial_offset_ - offset_in_block;  // 当前 Block 的起始 offset，应该是 32768 的倍数

  // Don't search a block if we'd be in the trailer
  if (offset_in_block > kBlockSize - 6) {   // 如果当前 Block 只剩下不到 6 bytes，那么直接跳到下一个 Block 起始位置
    block_start_location += kBlockSize;
  }

  end_of_buffer_offset_ = block_start_location;   // 设置当前 Reader 正在读取的 offset

  // Skip to start of first block that can contain the initial record
  if (block_start_location > 0) {
    Status skip_status = file_->Skip(block_start_location);   // seek 到当前 Block 开始位置，跳过已经读过的 Block
    if (!skip_status.ok()) {
      ReportDrop(block_start_location, skip_status);
      return false;
    }
  }

  return true;
}
~~~

这是之后调用的 `ReadPhysicalRecord()` 方法。
~~~c++
unsigned int Reader::ReadPhysicalRecord(Slice* result) {
  while (true) {
    if (buffer_.size() < kHeaderSize) {
      if (!eof_) {
        // Last read was a full read, so this is a trailer to skip
        buffer_.clear();
        Status status = file_->Read(kBlockSize, &buffer_, backing_store_);
        end_of_buffer_offset_ += buffer_.size();
        if (!status.ok()) {
          buffer_.clear();
          ReportDrop(kBlockSize, status);
          eof_ = true;
          return kEof;
        } else if (buffer_.size() < kBlockSize) {
          eof_ = true;
        }
        continue;
      } else {
        // Note that if buffer_ is non-empty, we have a truncated header at the
        // end of the file, which can be caused by the writer crashing in the
        // middle of writing the header. Instead of considering this an error,
        // just report EOF.
        buffer_.clear();
        return kEof;
      }
    }

    // Parse the header
    const char* header = buffer_.data();
    const uint32_t a = static_cast<uint32_t>(header[4]) & 0xff;
    const uint32_t b = static_cast<uint32_t>(header[5]) & 0xff;
    const unsigned int type = header[6];
    const uint32_t length = a | (b << 8);
    if (kHeaderSize + length > buffer_.size()) {
      size_t drop_size = buffer_.size();
      buffer_.clear();
      if (!eof_) {
        ReportCorruption(drop_size, "bad record length");
        return kBadRecord;
      }
      // If the end of the file has been reached without reading |length| bytes
      // of payload, assume the writer died in the middle of writing the record.
      // Don't report a corruption.
      return kEof;
    }

    if (type == kZeroType && length == 0) {
      // Skip zero length record without reporting any drops since
      // such records are produced by the mmap based writing code in
      // env_posix.cc that preallocates file regions.
      buffer_.clear();
      return kBadRecord;
    }

    // Check crc
    if (checksum_) {
      uint32_t expected_crc = crc32c::Unmask(DecodeFixed32(header));
      uint32_t actual_crc = crc32c::Value(header + 6, 1 + length);
      if (actual_crc != expected_crc) {
        // Drop the rest of the buffer since "length" itself may have
        // been corrupted and if we trust it, we could find some
        // fragment of a real log record that just happens to look
        // like a valid log record.
        size_t drop_size = buffer_.size();
        buffer_.clear();
        ReportCorruption(drop_size, "checksum mismatch");
        return kBadRecord;
      }
    }

    buffer_.remove_prefix(kHeaderSize + length);

    // Skip physical record that started before initial_offset_
    if (end_of_buffer_offset_ - buffer_.size() - kHeaderSize - length <
        initial_offset_) {
      result->clear();
      return kBadRecord;
    }

    *result = Slice(header + kHeaderSize, length);
    return type;
  }
}
~~~
